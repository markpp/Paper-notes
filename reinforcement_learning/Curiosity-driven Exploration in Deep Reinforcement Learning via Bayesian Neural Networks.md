# Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks
[arXiv](https://arxiv.org/abs/1602.02867)

### Implementation

[original](https://github.com/openai/vime)

### What

- Efficient exploration in high-dimensional and continuous spaces is presently an unsolved challenge in reinforcement learning. Without effective exploration methods our agents thrash around until they randomly stumble into rewarding situations. This is sufficient in many simple toy tasks but inadequate if we wish to apply these algorithms to complex settings with high-dimensional action spaces, as is common in robotics. In this paper, Rein Houthooft and colleagues propose VIME, a practical approach to exploration using uncertainty on generative models. VIME makes the agent self-motivated; it actively seeks out surprising state-actions. 
- VIME can improve a range of policy search methods and makes significant progress on more realistic tasks with sparse rewards

### How
-

### Experiments
-
